---
layout: post
title:  "Welcome to Llamabox!"
date:   2023-11-06 17:02:16 +0000
categories: jekyll update
---
L'addestramento di modelli di lingua di grandi dimensioni come LLaMa 2.0 o 
ChatGPT-3.5 da zero può essere un'impresa fuori portata per la maggiorparte di noi.

**llama** 
Un rapporto ha suggerito che il costo per addestrare vari modelli 
LLaMa (includendo le versioni da 7B, 13B, 33B, e 65B parametri) era di circa $7milioni.

**gpt3** 
L'articolo suggerisce anche che l'addestramento di un modello GPT 
con 500 miliardi di parametri su un cluster CS-2 a 
quattro nodi potrebbe richiedere circa un anno, 
con un costo associato di diversi milioni di dollari, se non di più​.

Dobbiamo quindi rassegnarci a fare fine-tuning su modelli altrui? Forse non è poi così male, ma l'AI hardcore non è una cosa per tutti, almeno per ora.
[Questo rapporto][link] fornisce altre utili informazioni su questo argomento.


[link]: https://www.nextplatform.com/2022/12/01/counting-the-cost-of-training-large-language-models/

