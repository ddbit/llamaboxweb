<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-12-19T14:17:37+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">LLAMABOX</title><subtitle>Viaggio nel mondo dell&apos;addestramento dei modelli di intelligenza artificiale</subtitle><entry><title type="html">Dalle Reti Neurali Ricorrenti (RNN) ai Transformer: La Svolta</title><link href="http://localhost:4000/jekyll/update/2023/11/07/Dalle-Reti-Neurali-Ricorrenti-(RNN)-ai-Transformer.html" rel="alternate" type="text/html" title="Dalle Reti Neurali Ricorrenti (RNN) ai Transformer: La Svolta" /><published>2023-11-07T18:02:16+01:00</published><updated>2023-11-07T18:02:16+01:00</updated><id>http://localhost:4000/jekyll/update/2023/11/07/Dalle%20Reti%20Neurali%20Ricorrenti%20(RNN)%20ai%20Transformer</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2023/11/07/Dalle-Reti-Neurali-Ricorrenti-(RNN)-ai-Transformer.html"><![CDATA[<p>All you need is love … ma non per l’AI. Piuttosto <a href="https://arxiv.org/abs/1706.03762">“Attention Is All You Need”</a> è il seminal paper del 2017 da cui inizia la svolta. Si definisce una nuova architettura di #naturallanguageprocessing basata sul concetto di “attenzione” che scala meglio delle precedenti soluzioni.</p>

<p>Una lettura densa ma interessante che consiglio a chi vuole iniziare a capire perché ChatGPT sa fare quello che sa fare.</p>

<p>Le <strong>Reti Neurali Ricorrenti (Recurrent Neural Networks, RNN)</strong> e i <strong>Transformer</strong> sono due architetture di rete neurale utilizzate per elaborare dati sequenziali, ma hanno differenze significative nella loro struttura e nel modo in cui gestiscono le informazioni.</p>

<h2 id="reti-neurali-ricorrenti-rnn">Reti Neurali Ricorrenti (RNN):</h2>

<ul>
  <li>Le RNN sono progettate per gestire sequenze di dati, come il testo o le serie temporali.</li>
  <li>Hanno un ciclo che consente alle informazioni di persistere, passando da un passo temporale al successivo. Questo ciclo può essere considerato come una memoria che mantiene informazioni sui passaggi precedenti.</li>
  <li>Le RNN soffrono spesso di problemi come la scomparsa o l’esplosione del gradiente, che rendono difficile l’apprendimento di dipendenze a lungo termine nei dati.</li>
  <li>Le varianti più avanzate di RNN, come le <strong>LSTM (Long Short-Term Memory)</strong> e le <strong>GRU (Gated Recurrent Units)</strong>, sono state sviluppate per mitigare questi problemi e sono in grado di catturare dipendenze a lungo termine meglio delle RNN standard.</li>
</ul>

<h2 id="transformer">Transformer:</h2>

<ul>
  <li>I Transformer sono stati introdotti nel paper “Attention is All You Need” di Vaswani et al. nel 2017 e sono diventati lo stato dell’arte per molte applicazioni di elaborazione del linguaggio naturale.</li>
  <li>A differenza delle RNN, i Transformer non utilizzano cicli e sono completamente basati su meccanismi di attenzione per pesare l’importanza di diverse parti di una sequenza.</li>
  <li>I Transformer sono in grado di gestire tutte le parti di una sequenza contemporaneamente (elaborazione parallela), il che li rende molto più veloci e efficienti rispetto alle RNN per sequenze lunghe.</li>
  <li>La struttura del Transformer gli permette di catturare dipendenze a lungo termine senza i problemi di scomparsa o esplosione del gradiente tipici delle RNN.</li>
</ul>

<p>In sintesi, mentre le RNN lavorano sequenzialmente e possono avere difficoltà con le dipendenze a lungo termine, i Transformer gestiscono le sequenze in modo parallelo e sono molto più efficaci nell’apprendere queste dipendenze, il che li rende particolarmente adatti per applicazioni come la traduzione automatica, la generazione di testo e altre complesse attività di elaborazione del linguaggio naturale.</p>

<h1 id="il-concetto-di-attention-nel-paper-attention-is-all-you-need">Il Concetto di “Attention” nel Paper “Attention Is All You Need”</h1>

<p>Il paper in questione si può considerare il punto di svolta nell’evoluzione dei modelli di linguaggio. Punto dal quale sono poi stati sviluppati i modelli LLM oggi in voga tra cui GPT e LLama.</p>

<p>Il concetto di “attention” nel documento <a href="https://arxiv.org/abs/1706.03762">“Attention Is All You Need”</a> si riferisce a un meccanismo che permette ai modelli di focalizzarsi su parti specifiche di un input quando eseguono una determinata compito. Di seguito è riportata una spiegazione dettagliata basata sulle informazioni trovate nel documento:</p>

<h2 id="scaled-dot-product-attention">Scaled Dot-Product Attention:</h2>

<ul>
  <li>Questo tipo di attenzione, chiamato “Scaled Dot-Product Attention”, è una componente chiave dell’architettura Transformer.</li>
  <li>L’input consiste in query e chiavi di dimensione ( d_k ), e valori di dimensione ( d_v ).</li>
  <li>Si calcolano i prodotti scalari delle query con tutte le chiavi, si divide ciascuno per ( \sqrt{d_k} ), e si applica una funzione softmax per ottenere i pesi sui valori.</li>
  <li>
    <p>In pratica, la funzione di attenzione viene calcolata su un insieme di query simultaneamente, raggruppate in una matrice Q. Anche le chiavi e i valori sono raggruppati in matrici K e V. Si calcola la matrice di output come segue:</p>

    <p>[ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V ]</p>
  </li>
</ul>

<h2 id="multi-head-attention">Multi-Head Attention:</h2>

<ul>
  <li>Il meccanismo di Multi-Head Attention consiste di diverse layer di attenzione che operano in parallelo.</li>
  <li>Questo approccio permette al modello di prestare attenzione a informazioni diverse da parti diverse della sequenza di input.</li>
  <li>Ogni “testa” di attenzione può catturare diversi tipi di relazioni tra i dati di input e output.</li>
</ul>

<h2 id="self-attention">Self-Attention:</h2>

<ul>
  <li>Il self-attention, a volte chiamato intra-attention, è un meccanismo di attenzione che collega diverse posizioni di una singola sequenza per calcolare una rappresentazione della sequenza.</li>
  <li>Questo permette al modello di considerare l’intera sequenza di input per ogni output, facilitando la cattura di dipendenze a lungo termine.</li>
</ul>

<h2 id="efficienza-del-transformer">Efficienza del Transformer:</h2>

<ul>
  <li>Il Transformer riduce il numero di operazioni necessarie per apprendere dipendenze tra posizioni distanti in una sequenza a un numero costante, a differenza delle RNN che richiedono un numero di operazioni proporzionale alla distanza tra le posizioni.</li>
  <li>Questo rende il Transformer più efficiente, specialmente per sequenze lunghe, poiché può gestire l’elaborazione in parallelo piuttosto che sequenzialmente.</li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[All you need is love … ma non per l’AI. Piuttosto “Attention Is All You Need” è il seminal paper del 2017 da cui inizia la svolta. Si definisce una nuova architettura di #naturallanguageprocessing basata sul concetto di “attenzione” che scala meglio delle precedenti soluzioni.]]></summary></entry><entry><title type="html">Welcome to Llamabox!</title><link href="http://localhost:4000/jekyll/update/2023/11/06/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Llamabox!" /><published>2023-11-06T18:02:16+01:00</published><updated>2023-11-06T18:02:16+01:00</updated><id>http://localhost:4000/jekyll/update/2023/11/06/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2023/11/06/welcome-to-jekyll.html"><![CDATA[<p>L’addestramento di modelli di lingua di grandi dimensioni come LLaMa 2.0 o 
ChatGPT-3.5 da zero può essere un’impresa fuori portata per la maggiorparte di noi.</p>

<p><strong>llama</strong> 
Un rapporto ha suggerito che il costo per addestrare vari modelli 
LLaMa (includendo le versioni da 7B, 13B, 33B, e 65B parametri) era di circa $7milioni.</p>

<p><strong>gpt3</strong> 
L’articolo suggerisce anche che l’addestramento di un modello GPT 
con 500 miliardi di parametri su un cluster CS-2 a 
quattro nodi potrebbe richiedere circa un anno, 
con un costo associato di diversi milioni di dollari, se non di più​.</p>

<p>Dobbiamo quindi rassegnarci a fare fine-tuning su modelli altrui? Forse non è poi così male, ma l’AI hardcore non è una cosa per tutti, almeno per ora.
<a href="https://www.nextplatform.com/2022/12/01/counting-the-cost-of-training-large-language-models/">Questo rapporto</a> fornisce altre utili informazioni su questo argomento.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[L’addestramento di modelli di lingua di grandi dimensioni come LLaMa 2.0 o ChatGPT-3.5 da zero può essere un’impresa fuori portata per la maggiorparte di noi.]]></summary></entry></feed>